RAW
device: cuda
	epoch 1 loss -> train: 3.3821	val: 1.8889
		saving model
	epoch 2 loss -> train: 1.9144	val: 1.3094
		saving model
	epoch 3 loss -> train: 1.4665	val: 1.0192
		saving model
	epoch 4 loss -> train: 1.2128	val: 0.8673
		saving model
	epoch 5 loss -> train: 1.0483	val: 0.7813
		saving model
	epoch 6 loss -> train: 0.9427	val: 0.6942
		saving model
	epoch 7 loss -> train: 0.8452	val: 0.6592
		saving model
	epoch 8 loss -> train: 0.7841	val: 0.6241
		saving model
	epoch 9 loss -> train: 0.7349	val: 0.5930
		saving model
	epoch 10 loss -> train: 0.6962	val: 0.5674
		saving model
	epoch 11 loss -> train: 0.6636	val: 0.5523
		saving model
	epoch 12 loss -> train: 0.6375	val: 0.5277
		saving model
	epoch 13 loss -> train: 0.6087	val: 0.5146
		saving model
	epoch 14 loss -> train: 0.5892	val: 0.4954
		saving model
	epoch 15 loss -> train: 0.5705	val: 0.4864
		saving model
	epoch 16 loss -> train: 0.5495	val: 0.4728
		saving model
	epoch 17 loss -> train: 0.5343	val: 0.4658
		saving model
	epoch 18 loss -> train: 0.5186	val: 0.4492
		saving model
	epoch 19 loss -> train: 0.5079	val: 0.4492
	epoch 20 loss -> train: 0.4944	val: 0.4354
		saving model
	epoch 21 loss -> train: 0.4828	val: 0.4332
		saving model
	epoch 22 loss -> train: 0.4747	val: 0.4171
		saving model
	epoch 23 loss -> train: 0.4623	val: 0.4205
	epoch 24 loss -> train: 0.4527	val: 0.4044
		saving model
	epoch 25 loss -> train: 0.4413	val: 0.4127
	epoch 26 loss -> train: 0.4402	val: 0.3956
		saving model
	epoch 27 loss -> train: 0.4300	val: 0.3991
	epoch 28 loss -> train: 0.4274	val: 0.3856
		saving model
	epoch 29 loss -> train: 0.4161	val: 0.3855
		saving model
	epoch 30 loss -> train: 0.4107	val: 0.3744
		saving model
	epoch 31 loss -> train: 0.4015	val: 0.3762
	epoch 32 loss -> train: 0.3938	val: 0.3677
		saving model
	epoch 33 loss -> train: 0.3872	val: 0.3690
	epoch 34 loss -> train: 0.3850	val: 0.3644
		saving model
	epoch 35 loss -> train: 0.3775	val: 0.3698
	epoch 36 loss -> train: 0.3805	val: 0.3765
	epoch 37 loss -> train: 0.3814	val: 0.3616
		saving model
	epoch 38 loss -> train: 0.3703	val: 0.3681
	epoch 39 loss -> train: 0.3671	val: 0.3601
		saving model
	epoch 40 loss -> train: 0.3649	val: 0.3564
		saving model
	epoch 41 loss -> train: 0.3553	val: 0.3506
		saving model
	epoch 42 loss -> train: 0.3544	val: 0.3470
		saving model
	epoch 43 loss -> train: 0.3483	val: 0.3444
		saving model
	epoch 44 loss -> train: 0.3396	val: 0.3406
		saving model
	epoch 45 loss -> train: 0.3360	val: 0.3353
		saving model
	epoch 46 loss -> train: 0.3316	val: 0.3368
	epoch 47 loss -> train: 0.3284	val: 0.3350
		saving model
	epoch 48 loss -> train: 0.3243	val: 0.3400
	epoch 49 loss -> train: 0.3230	val: 0.3342
		saving model
	epoch 50 loss -> train: 0.3211	val: 0.3494
	epoch 51 loss -> train: 0.3199	val: 0.3337
		saving model
	epoch 52 loss -> train: 0.3127	val: 0.3431
	epoch 53 loss -> train: 0.3101	val: 0.3316
		saving model
	epoch 54 loss -> train: 0.3126	val: 0.3370
	epoch 55 loss -> train: 0.3076	val: 0.3330
	epoch 56 loss -> train: 0.3066	val: 0.3446
	epoch 57 loss -> train: 0.3064	val: 0.3397
	epoch 58 loss -> train: 0.3080	val: 0.3580
	epoch 59 loss -> train: 0.3132	val: 0.3343
	epoch 60 loss -> train: 0.2994	val: 0.3359
	epoch 61 loss -> train: 0.2958	val: 0.3262
		saving model
	epoch 62 loss -> train: 0.2882	val: 0.3269
	epoch 63 loss -> train: 0.2849	val: 0.3245
		saving model
	epoch 64 loss -> train: 0.2853	val: 0.3262
	epoch 65 loss -> train: 0.2812	val: 0.3224
		saving model
	epoch 66 loss -> train: 0.2799	val: 0.3218
		saving model
	epoch 67 loss -> train: 0.2758	val: 0.3249
	epoch 68 loss -> train: 0.2721	val: 0.3221
	epoch 69 loss -> train: 0.2724	val: 0.3177
		saving model
	epoch 70 loss -> train: 0.2674	val: 0.3132
		saving model
	epoch 71 loss -> train: 0.2636	val: 0.3187
	epoch 72 loss -> train: 0.2615	val: 0.3309
	epoch 73 loss -> train: 0.2660	val: 0.3269
	epoch 74 loss -> train: 0.2629	val: 0.3287
	epoch 75 loss -> train: 0.2603	val: 0.3208
	epoch 76 loss -> train: 0.2569	val: 0.3133
	epoch 77 loss -> train: 0.2505	val: 0.3206
	epoch 78 loss -> train: 0.2503	val: 0.3156
	epoch 79 loss -> train: 0.2441	val: 0.3146
	epoch 80 loss -> train: 0.2444	val: 0.3123
		saving model
	epoch 81 loss -> train: 0.2411	val: 0.3239
	epoch 82 loss -> train: 0.2443	val: 0.3275
	epoch 83 loss -> train: 0.2503	val: 0.3474
	epoch 84 loss -> train: 0.2695	val: 0.3385
	epoch 85 loss -> train: 0.2588	val: 0.3479
	epoch 86 loss -> train: 0.2555	val: 0.3155
	epoch 87 loss -> train: 0.2407	val: 0.3250
	epoch 88 loss -> train: 0.2366	val: 0.3133
	epoch 89 loss -> train: 0.2330	val: 0.3171
	epoch 90 loss -> train: 0.2316	val: 0.3173
	epoch 91 loss -> train: 0.2289	val: 0.3225
	epoch 92 loss -> train: 0.2269	val: 0.3107
		saving model
	epoch 93 loss -> train: 0.2186	val: 0.3189
	epoch 94 loss -> train: 0.2212	val: 0.3195
	epoch 95 loss -> train: 0.2212	val: 0.3238
	epoch 96 loss -> train: 0.2179	val: 0.3192
	epoch 97 loss -> train: 0.2140	val: 0.3197
	epoch 98 loss -> train: 0.2135	val: 0.3169
	epoch 99 loss -> train: 0.2140	val: 0.3256
	epoch 100 loss -> train: 0.2126	val: 0.3312

*** TEST RESULTS ***
test loss:  0.2944136962890625

blurred and equalised
device: cuda
	epoch 1 loss -> train: 2.9242	val: 1.5676
		saving model
	epoch 2 loss -> train: 1.6524	val: 1.0285
		saving model
	epoch 3 loss -> train: 1.2627	val: 0.8378
		saving model
	epoch 4 loss -> train: 1.0601	val: 0.7431
		saving model
	epoch 5 loss -> train: 0.9354	val: 0.6866
		saving model
	epoch 6 loss -> train: 0.8396	val: 0.6388
		saving model
	epoch 7 loss -> train: 0.7713	val: 0.6142
		saving model
	epoch 8 loss -> train: 0.7282	val: 0.5798
		saving model
	epoch 9 loss -> train: 0.6910	val: 0.5629
		saving model
	epoch 10 loss -> train: 0.6526	val: 0.5340
		saving model
	epoch 11 loss -> train: 0.6273	val: 0.5178
		saving model
	epoch 12 loss -> train: 0.5999	val: 0.5048
		saving model
	epoch 13 loss -> train: 0.5765	val: 0.4890
		saving model
	epoch 14 loss -> train: 0.5559	val: 0.4755
		saving model
	epoch 15 loss -> train: 0.5402	val: 0.4645
		saving model
	epoch 16 loss -> train: 0.5249	val: 0.4490
		saving model
	epoch 17 loss -> train: 0.5077	val: 0.4385
		saving model
	epoch 18 loss -> train: 0.4941	val: 0.4311
		saving model
	epoch 19 loss -> train: 0.4876	val: 0.4242
		saving model
	epoch 20 loss -> train: 0.4792	val: 0.4138
		saving model
	epoch 21 loss -> train: 0.4659	val: 0.4089
		saving model
	epoch 22 loss -> train: 0.4562	val: 0.4073
		saving model
	epoch 23 loss -> train: 0.4466	val: 0.3937
		saving model
	epoch 24 loss -> train: 0.4428	val: 0.3929
		saving model
	epoch 25 loss -> train: 0.4328	val: 0.3897
		saving model
	epoch 26 loss -> train: 0.4276	val: 0.3818
		saving model
	epoch 27 loss -> train: 0.4204	val: 0.3745
		saving model
	epoch 28 loss -> train: 0.4142	val: 0.3811
	epoch 29 loss -> train: 0.4130	val: 0.3788
	epoch 30 loss -> train: 0.4058	val: 0.3713
		saving model
	epoch 31 loss -> train: 0.4011	val: 0.3697
		saving model
	epoch 32 loss -> train: 0.3925	val: 0.3624
		saving model
	epoch 33 loss -> train: 0.3886	val: 0.3573
		saving model
	epoch 34 loss -> train: 0.3820	val: 0.3537
		saving model
	epoch 35 loss -> train: 0.3790	val: 0.3552
	epoch 36 loss -> train: 0.3739	val: 0.3511
		saving model
	epoch 37 loss -> train: 0.3724	val: 0.3520
	epoch 38 loss -> train: 0.3702	val: 0.3546
	epoch 39 loss -> train: 0.3671	val: 0.3504
		saving model
	epoch 40 loss -> train: 0.3643	val: 0.3463
		saving model
	epoch 41 loss -> train: 0.3594	val: 0.3498
	epoch 42 loss -> train: 0.3574	val: 0.3411
		saving model
	epoch 43 loss -> train: 0.3491	val: 0.3465
	epoch 44 loss -> train: 0.3480	val: 0.3358
		saving model
	epoch 45 loss -> train: 0.3445	val: 0.3385
	epoch 46 loss -> train: 0.3411	val: 0.3396
	epoch 47 loss -> train: 0.3377	val: 0.3400
	epoch 48 loss -> train: 0.3334	val: 0.3327
		saving model
	epoch 49 loss -> train: 0.3293	val: 0.3382
	epoch 50 loss -> train: 0.3336	val: 0.3323
		saving model
	epoch 51 loss -> train: 0.3265	val: 0.3416
	epoch 52 loss -> train: 0.3278	val: 0.3383
	epoch 53 loss -> train: 0.3277	val: 0.3463
	epoch 54 loss -> train: 0.3296	val: 0.3448
	epoch 55 loss -> train: 0.3323	val: 0.3368
	epoch 56 loss -> train: 0.3233	val: 0.3324
	epoch 57 loss -> train: 0.3199	val: 0.3296
		saving model
	epoch 58 loss -> train: 0.3157	val: 0.3299
	epoch 59 loss -> train: 0.3168	val: 0.3243
		saving model
	epoch 60 loss -> train: 0.3046	val: 0.3184
		saving model
	epoch 61 loss -> train: 0.3016	val: 0.3142
		saving model
	epoch 62 loss -> train: 0.2993	val: 0.3138
		saving model
	epoch 63 loss -> train: 0.2967	val: 0.3154
	epoch 64 loss -> train: 0.2958	val: 0.3089
		saving model
	epoch 65 loss -> train: 0.2868	val: 0.3141
	epoch 66 loss -> train: 0.2870	val: 0.3123
	epoch 67 loss -> train: 0.2858	val: 0.3145
	epoch 68 loss -> train: 0.2835	val: 0.3113
	epoch 69 loss -> train: 0.2847	val: 0.3152
	epoch 70 loss -> train: 0.2842	val: 0.3169
	epoch 71 loss -> train: 0.2828	val: 0.3213
	epoch 72 loss -> train: 0.2824	val: 0.3093
	epoch 73 loss -> train: 0.2805	val: 0.3205
	epoch 74 loss -> train: 0.2751	val: 0.3096
	epoch 75 loss -> train: 0.2749	val: 0.3198
	epoch 76 loss -> train: 0.2779	val: 0.3153
	epoch 77 loss -> train: 0.2739	val: 0.3313
	epoch 78 loss -> train: 0.2755	val: 0.3097
	epoch 79 loss -> train: 0.2770	val: 0.3138
	epoch 80 loss -> train: 0.2680	val: 0.3186
	epoch 81 loss -> train: 0.2689	val: 0.3259
	epoch 82 loss -> train: 0.2723	val: 0.3317
	epoch 83 loss -> train: 0.2777	val: 0.3197
	epoch 84 loss -> train: 0.2726	val: 0.3242
	epoch 85 loss -> train: 0.2689	val: 0.3071
		saving model
	epoch 86 loss -> train: 0.2602	val: 0.3078
	epoch 87 loss -> train: 0.2545	val: 0.3074
	epoch 88 loss -> train: 0.2542	val: 0.2955
		saving model
	epoch 89 loss -> train: 0.2495	val: 0.3099
	epoch 90 loss -> train: 0.2520	val: 0.2998
	epoch 91 loss -> train: 0.2490	val: 0.2998
	epoch 92 loss -> train: 0.2396	val: 0.3076
	epoch 93 loss -> train: 0.2416	val: 0.3036
	epoch 94 loss -> train: 0.2376	val: 0.3052
	epoch 95 loss -> train: 0.2422	val: 0.3151
	epoch 96 loss -> train: 0.2446	val: 0.2993
	epoch 97 loss -> train: 0.2362	val: 0.3096
	epoch 98 loss -> train: 0.2402	val: 0.3141
	epoch 99 loss -> train: 0.2497	val: 0.3367
	epoch 100 loss -> train: 0.2537	val: 0.3018

*** TEST RESULTS ***
test loss:  0.283528173828125

edge detected
device: cuda
	epoch 1 loss -> train: 2.7331	val: 1.6499
		saving model
	epoch 2 loss -> train: 1.6360	val: 1.1363
		saving model
	epoch 3 loss -> train: 1.2138	val: 0.8986
		saving model
	epoch 4 loss -> train: 1.0387	val: 0.8129
		saving model
	epoch 5 loss -> train: 0.9178	val: 0.7337
		saving model
	epoch 6 loss -> train: 0.8249	val: 0.6849
		saving model
	epoch 7 loss -> train: 0.7570	val: 0.6334
		saving model
	epoch 8 loss -> train: 0.7080	val: 0.6048
		saving model
	epoch 9 loss -> train: 0.6673	val: 0.5774
		saving model
	epoch 10 loss -> train: 0.6295	val: 0.5573
		saving model
	epoch 11 loss -> train: 0.6069	val: 0.5407
		saving model
	epoch 12 loss -> train: 0.5842	val: 0.5232
		saving model
	epoch 13 loss -> train: 0.5618	val: 0.5107
		saving model
	epoch 14 loss -> train: 0.5430	val: 0.5019
		saving model
	epoch 15 loss -> train: 0.5255	val: 0.4910
		saving model
	epoch 16 loss -> train: 0.5065	val: 0.4849
		saving model
	epoch 17 loss -> train: 0.4928	val: 0.4772
		saving model
	epoch 18 loss -> train: 0.4820	val: 0.4700
		saving model
	epoch 19 loss -> train: 0.4671	val: 0.4657
		saving model
	epoch 20 loss -> train: 0.4570	val: 0.4605
		saving model
	epoch 21 loss -> train: 0.4476	val: 0.4567
		saving model
	epoch 22 loss -> train: 0.4349	val: 0.4522
		saving model
	epoch 23 loss -> train: 0.4214	val: 0.4508
		saving model
	epoch 24 loss -> train: 0.4120	val: 0.4474
		saving model
	epoch 25 loss -> train: 0.4039	val: 0.4465
		saving model
	epoch 26 loss -> train: 0.3950	val: 0.4448
		saving model
	epoch 27 loss -> train: 0.3875	val: 0.4456
	epoch 28 loss -> train: 0.3764	val: 0.4405
		saving model
	epoch 29 loss -> train: 0.3672	val: 0.4421
	epoch 30 loss -> train: 0.3594	val: 0.4378
		saving model
	epoch 31 loss -> train: 0.3507	val: 0.4447
	epoch 32 loss -> train: 0.3423	val: 0.4419
	epoch 33 loss -> train: 0.3404	val: 0.4471
	epoch 34 loss -> train: 0.3301	val: 0.4432
	epoch 35 loss -> train: 0.3229	val: 0.4483
	epoch 36 loss -> train: 0.3174	val: 0.4343
		saving model
	epoch 37 loss -> train: 0.3083	val: 0.4384
	epoch 38 loss -> train: 0.3019	val: 0.4310
		saving model
	epoch 39 loss -> train: 0.2917	val: 0.4334
	epoch 40 loss -> train: 0.2801	val: 0.4274
		saving model
	epoch 41 loss -> train: 0.2692	val: 0.4301
	epoch 42 loss -> train: 0.2608	val: 0.4254
		saving model
	epoch 43 loss -> train: 0.2515	val: 0.4296
	epoch 44 loss -> train: 0.2425	val: 0.4314
	epoch 45 loss -> train: 0.2327	val: 0.4383
	epoch 46 loss -> train: 0.2265	val: 0.4397
	epoch 47 loss -> train: 0.2219	val: 0.4429
	epoch 48 loss -> train: 0.2121	val: 0.4415
	epoch 49 loss -> train: 0.2041	val: 0.4491
	epoch 50 loss -> train: 0.1963	val: 0.4554
	epoch 51 loss -> train: 0.1895	val: 0.4618
	epoch 52 loss -> train: 0.1847	val: 0.4686
	epoch 53 loss -> train: 0.1763	val: 0.4690
	epoch 54 loss -> train: 0.1670	val: 0.4768
	epoch 55 loss -> train: 0.1632	val: 0.4846
	epoch 56 loss -> train: 0.1542	val: 0.4896
	epoch 57 loss -> train: 0.1510	val: 0.5015
	epoch 58 loss -> train: 0.1429	val: 0.5095
	epoch 59 loss -> train: 0.1359	val: 0.5270
	epoch 60 loss -> train: 0.1355	val: 0.5546
	epoch 61 loss -> train: 0.1393	val: 0.5537
	epoch 62 loss -> train: 0.1329	val: 0.5180
	epoch 63 loss -> train: 0.1141	val: 0.5344
	epoch 64 loss -> train: 0.1138	val: 0.5401
	epoch 65 loss -> train: 0.1032	val: 0.5518
	epoch 66 loss -> train: 0.0977	val: 0.5485
	epoch 67 loss -> train: 0.0912	val: 0.5565
	epoch 68 loss -> train: 0.0862	val: 0.5748
	epoch 69 loss -> train: 0.0798	val: 0.5821
	epoch 70 loss -> train: 0.0759	val: 0.5844
	epoch 71 loss -> train: 0.0760	val: 0.6016
	epoch 72 loss -> train: 0.0717	val: 0.6104
	epoch 73 loss -> train: 0.0669	val: 0.6254
	epoch 74 loss -> train: 0.0637	val: 0.6306
	epoch 75 loss -> train: 0.0599	val: 0.6439
	epoch 76 loss -> train: 0.0575	val: 0.6548
	epoch 77 loss -> train: 0.0559	val: 0.6522
	epoch 78 loss -> train: 0.0521	val: 0.6569
	epoch 79 loss -> train: 0.0496	val: 0.6828
	epoch 80 loss -> train: 0.0493	val: 0.6874
	epoch 81 loss -> train: 0.0456	val: 0.6996
	epoch 82 loss -> train: 0.0440	val: 0.6999
	epoch 83 loss -> train: 0.0407	val: 0.7149
	epoch 84 loss -> train: 0.0385	val: 0.7122
	epoch 85 loss -> train: 0.0383	val: 0.7378
	epoch 86 loss -> train: 0.0359	val: 0.7390
	epoch 87 loss -> train: 0.0367	val: 0.7570
	epoch 88 loss -> train: 0.0344	val: 0.7526
	epoch 89 loss -> train: 0.0337	val: 0.7668
	epoch 90 loss -> train: 0.0335	val: 0.7681
	epoch 91 loss -> train: 0.0327	val: 0.7666
	epoch 92 loss -> train: 0.0317	val: 0.7574
	epoch 93 loss -> train: 0.0294	val: 0.7889
	epoch 94 loss -> train: 0.0285	val: 0.7947
	epoch 95 loss -> train: 0.0280	val: 0.8180
	epoch 96 loss -> train: 0.0299	val: 0.8094
	epoch 97 loss -> train: 0.0295	val: 0.8348
	epoch 98 loss -> train: 0.0287	val: 0.8087
	epoch 99 loss -> train: 0.0266	val: 0.8190
	epoch 100 loss -> train: 0.0280	val: 0.8140

*** TEST RESULTS ***
test loss:  0.4027093505859375

hog features
device: cuda
	epoch 1 loss -> train: 2.3034	val: 2.2917
		saving model
	epoch 2 loss -> train: 2.2856	val: 2.2632
		saving model
	epoch 3 loss -> train: 2.2525	val: 2.2097
		saving model
	epoch 4 loss -> train: 2.1886	val: 2.1050
		saving model
	epoch 5 loss -> train: 2.0677	val: 1.9237
		saving model
	epoch 6 loss -> train: 1.8742	val: 1.6787
		saving model
	epoch 7 loss -> train: 1.6360	val: 1.4313
		saving model
	epoch 8 loss -> train: 1.4183	val: 1.2184
		saving model
	epoch 9 loss -> train: 1.2506	val: 1.0685
		saving model
	epoch 10 loss -> train: 1.1402	val: 0.9788
		saving model
	epoch 11 loss -> train: 1.0602	val: 0.9193
		saving model
	epoch 12 loss -> train: 0.9957	val: 0.8804
		saving model
	epoch 13 loss -> train: 0.9479	val: 0.8506
		saving model
	epoch 14 loss -> train: 0.9057	val: 0.8219
		saving model
	epoch 15 loss -> train: 0.8685	val: 0.7945
		saving model
	epoch 16 loss -> train: 0.8381	val: 0.7667
		saving model
	epoch 17 loss -> train: 0.8088	val: 0.7442
		saving model
	epoch 18 loss -> train: 0.7820	val: 0.7216
		saving model
	epoch 19 loss -> train: 0.7552	val: 0.7019
		saving model
	epoch 20 loss -> train: 0.7388	val: 0.6832
		saving model
	epoch 21 loss -> train: 0.7186	val: 0.6688
		saving model
	epoch 22 loss -> train: 0.7022	val: 0.6528
		saving model
	epoch 23 loss -> train: 0.6863	val: 0.6409
		saving model
	epoch 24 loss -> train: 0.6692	val: 0.6275
		saving model
	epoch 25 loss -> train: 0.6576	val: 0.6179
		saving model
	epoch 26 loss -> train: 0.6466	val: 0.6068
		saving model
	epoch 27 loss -> train: 0.6348	val: 0.6007
		saving model
	epoch 28 loss -> train: 0.6255	val: 0.5919
		saving model
	epoch 29 loss -> train: 0.6210	val: 0.5874
		saving model
	epoch 30 loss -> train: 0.6109	val: 0.5755
		saving model
	epoch 31 loss -> train: 0.6015	val: 0.5736
		saving model
	epoch 32 loss -> train: 0.5973	val: 0.5627
		saving model
	epoch 33 loss -> train: 0.5874	val: 0.5614
		saving model
	epoch 34 loss -> train: 0.5807	val: 0.5508
		saving model
	epoch 35 loss -> train: 0.5757	val: 0.5529
	epoch 36 loss -> train: 0.5684	val: 0.5401
		saving model
	epoch 37 loss -> train: 0.5629	val: 0.5433
	epoch 38 loss -> train: 0.5584	val: 0.5306
		saving model
	epoch 39 loss -> train: 0.5534	val: 0.5336
	epoch 40 loss -> train: 0.5469	val: 0.5219
		saving model
	epoch 41 loss -> train: 0.5435	val: 0.5264
	epoch 42 loss -> train: 0.5386	val: 0.5148
		saving model
	epoch 43 loss -> train: 0.5339	val: 0.5182
	epoch 44 loss -> train: 0.5315	val: 0.5059
		saving model
	epoch 45 loss -> train: 0.5267	val: 0.5092
	epoch 46 loss -> train: 0.5208	val: 0.4980
		saving model
	epoch 47 loss -> train: 0.5157	val: 0.4976
		saving model
	epoch 48 loss -> train: 0.5114	val: 0.4902
		saving model
	epoch 49 loss -> train: 0.5070	val: 0.4871
		saving model
	epoch 50 loss -> train: 0.5014	val: 0.4820
		saving model
	epoch 51 loss -> train: 0.4991	val: 0.4797
		saving model
	epoch 52 loss -> train: 0.4948	val: 0.4767
		saving model
	epoch 53 loss -> train: 0.4906	val: 0.4728
		saving model
	epoch 54 loss -> train: 0.4859	val: 0.4732
	epoch 55 loss -> train: 0.4832	val: 0.4675
		saving model
	epoch 56 loss -> train: 0.4810	val: 0.4666
		saving model
	epoch 57 loss -> train: 0.4755	val: 0.4624
		saving model
	epoch 58 loss -> train: 0.4773	val: 0.4637
	epoch 59 loss -> train: 0.4737	val: 0.4586
		saving model
	epoch 60 loss -> train: 0.4700	val: 0.4620
	epoch 61 loss -> train: 0.4677	val: 0.4555
		saving model
	epoch 62 loss -> train: 0.4657	val: 0.4583
	epoch 63 loss -> train: 0.4613	val: 0.4544
		saving model
	epoch 64 loss -> train: 0.4632	val: 0.4542
		saving model
	epoch 65 loss -> train: 0.4590	val: 0.4508
		saving model
	epoch 66 loss -> train: 0.4572	val: 0.4459
		saving model
	epoch 67 loss -> train: 0.4538	val: 0.4398
		saving model
	epoch 68 loss -> train: 0.4487	val: 0.4391
		saving model
	epoch 69 loss -> train: 0.4459	val: 0.4330
		saving model
	epoch 70 loss -> train: 0.4438	val: 0.4314
		saving model
	epoch 71 loss -> train: 0.4405	val: 0.4297
		saving model
	epoch 72 loss -> train: 0.4378	val: 0.4278
		saving model
	epoch 73 loss -> train: 0.4359	val: 0.4258
		saving model
	epoch 74 loss -> train: 0.4326	val: 0.4228
		saving model
	epoch 75 loss -> train: 0.4296	val: 0.4217
		saving model
	epoch 76 loss -> train: 0.4287	val: 0.4191
		saving model
	epoch 77 loss -> train: 0.4283	val: 0.4183
		saving model
	epoch 78 loss -> train: 0.4230	val: 0.4164
		saving model
	epoch 79 loss -> train: 0.4239	val: 0.4143
		saving model
	epoch 80 loss -> train: 0.4208	val: 0.4125
		saving model
	epoch 81 loss -> train: 0.4187	val: 0.4151
	epoch 82 loss -> train: 0.4177	val: 0.4100
		saving model
	epoch 83 loss -> train: 0.4150	val: 0.4083
		saving model
	epoch 84 loss -> train: 0.4135	val: 0.4086
	epoch 85 loss -> train: 0.4120	val: 0.4058
		saving model
	epoch 86 loss -> train: 0.4100	val: 0.4030
		saving model
	epoch 87 loss -> train: 0.4073	val: 0.4041
	epoch 88 loss -> train: 0.4043	val: 0.3997
		saving model
	epoch 89 loss -> train: 0.4042	val: 0.4025
	epoch 90 loss -> train: 0.4029	val: 0.3980
		saving model
	epoch 91 loss -> train: 0.4012	val: 0.3984
	epoch 92 loss -> train: 0.4007	val: 0.3958
		saving model
	epoch 93 loss -> train: 0.3961	val: 0.3957
		saving model
	epoch 94 loss -> train: 0.3968	val: 0.3950
		saving model
	epoch 95 loss -> train: 0.3931	val: 0.3962
	epoch 96 loss -> train: 0.3949	val: 0.3987
	epoch 97 loss -> train: 0.3928	val: 0.3966
	epoch 98 loss -> train: 0.3917	val: 0.3971
	epoch 99 loss -> train: 0.3906	val: 0.3983
	epoch 100 loss -> train: 0.3909	val: 0.3972

*** TEST RESULTS ***
test loss:  0.372340185546875
